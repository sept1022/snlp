{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align}\n",
       "P(w_n|w_1 \\cdots w_{n-1})\\ =\\ \\frac{w_1 \\cdots w_{n}}{P(w_1 \\cdots w_{n-1})} \n",
       "\\end{align}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{align}\n",
    "P(w_n|w_1 \\cdots w_{n-1})\\ =\\ \\frac{w_1 \\cdots w_{n}}{P(w_1 \\cdots w_{n-1})} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.external import mathjax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Notaion|Desc|\n",
    "|----------------|-----------------------------------------------------------------|\n",
    "|$N$|Number of training instances|\n",
    "|$B$|Number of bins training instances are divided into|\n",
    "|$w_{1n}$|An n-gram $w_1 \\cdots w_{n}$ in traging text|\n",
    "|$C(w_1 \\cdots w_n)$|Frequency of n-gram $w_1 \\cdots w_n$ in training text|\n",
    "|r|Frequence of an n-gram|\n",
    "|$f(\\cdot)$|Frequency estimate of a model|\n",
    "|$T_r$|Total count of n-grams of frequency $$r$$ in further data|\n",
    "|$h$|'history' of preceding words|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    fin = open(path, 'r')\n",
    "    return {line.split('\\t')[0]: int(line.split('\\t')[1]) for line in fin.read().split('\\n')}\n",
    "\n",
    "unigram_path = 'unigram.txt'\n",
    "unigram_model = load_model(unigram_path)\n",
    "\n",
    "bigram_path = 'bigram.txt'\n",
    "bigram_model = load_model(bigram_path)\n",
    "\n",
    "trigram_path = 'trigram.txt'\n",
    "trigram_model = load_model(trigram_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- maximum likelyhood estimate(MLE)\n",
    "\n",
    "$$P_{MLE}(w_1 \\cdots w_{n})\\ =\\ \\frac{C(w_1 \\cdots w_{n})}{N}$$\n",
    "\n",
    "$$P_{MLE}(w_n|w_1 \\cdots w_{n-1})\\ =\\ \\frac{C(w_1 \\cdots w_{n})}{C(w_1 \\cdots w_{n-1})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 94805), ('Emma', 865)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unigram_model.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N= 2334432\n",
      "      word unigram  bigram trigram\n",
      "       <s> 0.04061 \n",
      "        In 0.00066 0.00746 \n",
      "    person 0.00016 0.00000 0.00000 \n",
      "       she 0.00283 0.01053  unseen \n",
      "       was 0.00738 0.10506 0.25000 \n",
      "  inferior 0.00002 0.00000 0.00000 \n",
      "        to 0.01871 0.21053  unseen \n",
      "      both 0.00041 0.00027 0.00000 \n",
      "   sisters 0.00006 0.00000 0.00000 \n",
      "      </s> 0.04061 0.11194  unseen \n"
     ]
    }
   ],
   "source": [
    "N = 0\n",
    "for _, count in unigram_model.items():\n",
    "    N += int(count)\n",
    "    \n",
    "print('N=', N)\n",
    "\n",
    "def get_prob(now, history, model, history_model):\n",
    "    history = ' '.join(history)\n",
    "    now = history + ' ' + now\n",
    "    print(history)\n",
    "    print(now)\n",
    "\n",
    "def get_sentence_prob(sentence):\n",
    "    sentence = sentence.split()\n",
    "    sentence.insert(0, '<s>')\n",
    "    sentence.append('</s>')\n",
    "    \n",
    "    print('%10s%8s%8s%8s' %('word', 'unigram', 'bigram', 'trigram'))\n",
    "    for i in range(0, len(sentence)):\n",
    "        print('%10s %0.5f' % (sentence[i], unigram_model[sentence[i]]/N), end=' ')\n",
    "        \n",
    "        if i > 0:\n",
    "            hist = sentence[i-1]\n",
    "            bigram = ' '.join(sentence[i-1:i+1])\n",
    "            if bigram not in bigram_model:\n",
    "                print('%0.5f' % 0, end=' ')\n",
    "            else:\n",
    "                print('%0.5f' % (bigram_model[bigram]/unigram_model[hist]), end=' ')\n",
    "        \n",
    "        if i > 1:\n",
    "            hist = ' '.join(sentence[i-2:i])\n",
    "            trigram = ' '.join(sentence[i-2:i+1])\n",
    "            if hist not in bigram_model:\n",
    "                print('%7s' % 'unseen', end=' ')\n",
    "            elif trigram not in trigram_model:\n",
    "                print('%0.5f' % 0, end=' ')\n",
    "            else:\n",
    "                print('%0.5f' % (trigram_model[trigram]/bigram_model[hist]), end=' ')\n",
    "\n",
    "        print()\n",
    "sentence = 'In person she was inferior to both sisters'\n",
    "get_sentence_prob(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
